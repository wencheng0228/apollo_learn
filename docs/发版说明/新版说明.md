## 重要更新

Apollo 开源平台 9.0 进一步聚焦开发者扩展开发与调试体验，致力于为自动驾驶开发人员提供统一的开发工具平台和易扩展的 PnC、感知软件框架接口。新版本基于包管理重塑了 PnC、感知扩展开发模式：根据业务逻辑优化了组件的拆分和配置管理，更易调用；除了组件扩展方式，新增更轻量化的插件扩展方式，更易扩展。新版本推出了全新的开发者工具 Dreamview+，引入模式让多场景使用更便捷，引入面板布局让开发者随心自定义可视化，引入资源中心提供更丰富开发资源。此外，新版本升级了LiDAR、Camera检测模型效果更优，并开放了增量训练方法方便扩展；同时，新增了对4D毫米波雷达的支持。最后，新版本适配了ARM架构，并支持在Orin下编译和运行，为开发者提供了更多样的设备选择。

Apollo 开源平台 9.0 的主要新特征如下：

## 基于包管理的 PnC 扩展开发范式

- 统一的对外接口：接口统一封装在 external_command 模块处理，解耦了上层业务调用和 PNC 模块，同时便于用户自定义扩展接口和底盘命令。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo规划实践>基于命令发布开发>开发模式说明](docs/应用实践/开发调试教程/Apollo规划实践/基于命令发布开发/开发模式说明.md)

- 全新插件扩展机制：将 scenario，task 和 traffic rules 插件化，方便开发者开发部署自己的插件，通过配置流程来启动运行插件。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo规划实践>基于插件进行开发>开发模式说明](docs/应用实践/开发调试教程/Apollo规划实践/基于插件进行开发/开发模式说明.md)

- 分级参数配置机制：划分全局参数和局部参数，局部参数放在插件中独立管理，便于开发者查询和修改。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo规划实践>基于配置参数开发>开发模式说明](docs/应用实践/开发调试教程/Apollo规划实践/基于配置参数开发/开发模式说明.md)

## 基于包管理的感知扩展开发范式

- 功能组件拆分：从功能层面对激光雷达、相机和红绿灯检测拆分为小的功能组件，每个组件功能更加内聚，开发者可以灵活的组合和定制不同的算法流程，来满足当前场景的需求。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo感知实践>基于组件进行开发>组件开发模式说明](docs/应用实践/开发调试教程/Apollo感知实践/基于组件进行开发/组件开发模式说明.md)

- 插件扩展机制：除组件开发模式外，新增插件开发模式，方便基于现有感知框架下替换算法，提高模块的复用性。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo感知实践>基于插件进行开发>插件开发模式说明](docs/应用实践/开发调试教程/Apollo感知实践/基于插件进行开发/插件开发模式说明.md)

- 配置简化统一：针对感知相关配置做了统一管理，并提供详细的参数说明与修改文档，方便开发者随时查阅修改。相关信息及实践可参阅：
  [应用实践>开发调试教程>Apollo感知实践>基于配置参数开发>激光雷达参数介绍](docs/应用实践/开发调试教程/Apollo感知实践/基于配置参数开发/激光雷达参数介绍.md)

## 全新打造的 Dreamview Plus 开发者工具

- 基于模式的多场景使用更便捷：以感知、PnC 、实车等具体开发场景作为模式分类，精简各类模式下的使用流程，带来无缝且直观的操作体验。

- 基于面板的布局可视化更灵活：将每项可视化工具和功能均封装成独立的面板，支持自由配置可视化面板的布局、各面板内容以及大小，方便开发者自定义操作界面。

- 引入资源中心数据更丰富：进一步加强与 Studio 云端资源互动，可一键下载各类资源，如地图、场景、车辆配置、数据包等，方便开发调试。

- 了解Dreamview，可参阅：
  [工具使用>Dreamview+>Dreamview+ 概述](docs/工具使用/Dreamview+/Dreamview+ 概述.md)

- Dreamview快速体验可参阅：
  [应用实践>开发调试教程>Dreamview+>Dreamview +快速体验](docs/应用实践/开发调试教程/Dreamview+/Dreamview +快速使用.md)

## 感知模型全面升级，支持增量训练

- 全新模型效果更优：引入效果更好的、泛化性更强的模型。在激光雷达检测方向，采用 CenterPoint 替换了 CNNSeg 模型；相机检测方向，采用 YOLOX+YOLO3D 替换了原 YOLO 模型。

- 提供增量训练易扩展：通过使用少量标注数据与 Apollo 预训练模型，可显著提升特定目标和特定场景下的检测能力。训练代码完全开源，开发者可独立自主完成模型训练。

- 支持 4D 毫米波雷达：从硬件驱动到感知模型层，增加了对 4D 毫米波的支持，可以测量目标高度信息，同时实现更高的角度分辨率、输出更密集的点云；有利于使用深度学习的 3D 目标检测方法进行更精确的障碍物检测，提高自动驾驶车辆在雨雪雾等天气下的安全性。
